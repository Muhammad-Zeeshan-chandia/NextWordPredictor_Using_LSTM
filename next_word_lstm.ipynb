{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa25176",
   "metadata": {},
   "source": [
    "#### **Next Word Predictor Using LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80c7e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes=\"\"\"Jokes Collection\n",
    "General Jokes\n",
    "Why don’t scientists trust atoms?\n",
    "Because they make up everything!\n",
    "\n",
    "Why did the math book look sad?\n",
    "Because it had too many problems.\n",
    "\n",
    "Why did the scarecrow win an award?\n",
    "Because he was outstanding in his field.\n",
    "\n",
    "Why don’t skeletons fight each other?\n",
    "Because they don’t have the guts.\n",
    "\n",
    "Why did the bicycle fall over?\n",
    "Because it was two-tired.\n",
    "\n",
    "What do you call fake spaghetti?\n",
    "An impasta.\n",
    "\n",
    "Why did the coffee file a police report?\n",
    "It got mugged.\n",
    "\n",
    "What do you call cheese that isn’t yours?\n",
    "Nacho cheese.\n",
    "\n",
    "Why don't eggs tell jokes?\n",
    "Because they’d crack each other up.\n",
    "\n",
    "Why did the tomato turn red?\n",
    "Because it saw the salad dressing.\n",
    "\n",
    "Tech & Nerdy Jokes\n",
    "Why was the computer cold?\n",
    "Because it left its Windows open.\n",
    "\n",
    "Why don’t programmers like nature?\n",
    "It has too many bugs.\n",
    "\n",
    "Why do Java developers wear glasses?\n",
    "Because they don’t C#.\n",
    "\n",
    "Why was the cell phone wearing glasses?\n",
    "Because it lost its contacts.\n",
    "\n",
    "Why did the computer go to therapy?\n",
    "It had a hard drive.\n",
    "\n",
    "Why did the PowerPoint Presentation cross the road?\n",
    "To get to the other slide.\n",
    "\n",
    "What’s a computer’s favorite snack?\n",
    "Microchips.\n",
    "\n",
    "Why can’t you trust an atom?\n",
    "They make up everything.\n",
    "\n",
    "What’s a coder’s favorite hangout place?\n",
    "The Foo Bar.\n",
    "\n",
    "Why did the tech guy break up with his girlfriend?\n",
    "Too many arguments.\n",
    "\n",
    "Puns & Wordplay\n",
    "What did one wall say to the other wall?\n",
    "I’ll meet you at the corner.\n",
    "\n",
    "What do you call a fish wearing a bowtie?\n",
    "Sofishticated.\n",
    "\n",
    "How do you organize a space party?\n",
    "You planet.\n",
    "\n",
    "I would tell you a construction joke…\n",
    "But I’m still working on it.\n",
    "\n",
    "I used to play piano by ear…\n",
    "Now I use my hands.\n",
    "\n",
    "Why can’t your nose be 12 inches long?\n",
    "Because then it would be a foot.\n",
    "\n",
    "What happens when frogs park illegally?\n",
    "They get toad.\n",
    "\n",
    "Did you hear the rumor about butter?\n",
    "Well, I’m not going to spread it.\n",
    "\n",
    "I used to be addicted to soap…\n",
    "But I’m clean now.\n",
    "\n",
    "Why don’t oysters donate to charity?\n",
    "Because they’re shellfish.\n",
    "\n",
    "Animal Jokes\n",
    "Why do cows wear bells?\n",
    "Because their horns don’t work.\n",
    "\n",
    "Why did the chicken go to the séance?\n",
    "To talk to the other side.\n",
    "\n",
    "How do you count cows?\n",
    "With a cowculator.\n",
    "\n",
    "What do you call an alligator in a vest?\n",
    "An investigator.\n",
    "\n",
    "Why don’t elephants use computers?\n",
    "They’re afraid of the mouse.\n",
    "\n",
    "Why do seagulls fly over the sea?\n",
    "Because if they flew over the bay, they’d be bagels.\n",
    "\n",
    "What do you get from a pampered cow?\n",
    "Spoiled milk.\n",
    "\n",
    "Why did the cat sit on the computer?\n",
    "To keep an eye on the mouse.\n",
    "\n",
    "Why did the fish blush?\n",
    "Because it saw the ocean’s bottom.\n",
    "\n",
    "Why don’t dogs make good dancers?\n",
    "Because they have two left feet.\n",
    "\n",
    "Office & Work Jokes\n",
    "Why did the employee get fired from the calendar factory?\n",
    "He took a few days off.\n",
    "\n",
    "Why did the banker quit his job?\n",
    "He lost interest.\n",
    "\n",
    "Why did the clock get promoted?\n",
    "It always worked overtime.\n",
    "\n",
    "Why don’t bosses like long jokes?\n",
    "Because they drag on.\n",
    "\n",
    "Why did the stapler break up with the paper?\n",
    "It found it too clingy.\n",
    "\n",
    "What did the pen say to the pencil?\n",
    "You're pointless.\n",
    "\n",
    "Why was the office so cold?\n",
    "Because they left too many Windows open.\n",
    "\n",
    "What’s a ghost’s favorite office task?\n",
    "Spook-taking.\n",
    "\n",
    "Why did the intern bring a ladder to work?\n",
    "He wanted to climb the corporate ladder.\n",
    "\n",
    "Why don’t meetings ever end on time?\n",
    "Because time flies when no one’s paying attention.\n",
    "\n",
    "Dad Jokes\n",
    "What do you call a factory that makes okay products?\n",
    "A satisfactory.\n",
    "\n",
    "Did you hear about the restaurant on the moon?\n",
    "Great food, no atmosphere.\n",
    "\n",
    "What do you call a can opener that doesn’t work?\n",
    "A can’t opener.\n",
    "\n",
    "What’s orange and sounds like a parrot?\n",
    "A carrot.\n",
    "\n",
    "Want to hear a joke about construction?\n",
    "Sorry, I’m still working on it.\n",
    "\n",
    "What’s brown and sticky?\n",
    "A stick.\n",
    "\n",
    "I told my wife she was drawing her eyebrows too high…\n",
    "She looked surprised.\n",
    "\n",
    "What do you call a pile of cats?\n",
    "A meow-tain.\n",
    "\n",
    "Why couldn’t the bicycle find its way home?\n",
    "Because it lost its bearings.\n",
    "\n",
    "Why did the dad bring a ladder to the bar?\n",
    "Because he heard the drinks were on the house.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "239b2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef15bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([jokes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94b0d3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'why': 2,\n",
       " 'a': 3,\n",
       " 'because': 4,\n",
       " 'did': 5,\n",
       " 'to': 6,\n",
       " 'it': 7,\n",
       " 'you': 8,\n",
       " 'do': 9,\n",
       " 'don’t': 10,\n",
       " 'what': 11,\n",
       " 'they': 12,\n",
       " 'jokes': 13,\n",
       " 'on': 14,\n",
       " 'call': 15,\n",
       " 'too': 16,\n",
       " 'an': 17,\n",
       " 'was': 18,\n",
       " 'up': 19,\n",
       " 'he': 20,\n",
       " 'other': 21,\n",
       " 'get': 22,\n",
       " 'what’s': 23,\n",
       " 'i': 24,\n",
       " 'many': 25,\n",
       " 'its': 26,\n",
       " 'i’m': 27,\n",
       " 'be': 28,\n",
       " 'work': 29,\n",
       " 'make': 30,\n",
       " 'his': 31,\n",
       " 'over': 32,\n",
       " 'that': 33,\n",
       " 'computer': 34,\n",
       " 'left': 35,\n",
       " 'like': 36,\n",
       " 'lost': 37,\n",
       " 'favorite': 38,\n",
       " 'can’t': 39,\n",
       " 'with': 40,\n",
       " 'hear': 41,\n",
       " 'about': 42,\n",
       " 'office': 43,\n",
       " 'ladder': 44,\n",
       " 'trust': 45,\n",
       " 'everything': 46,\n",
       " 'had': 47,\n",
       " 'in': 48,\n",
       " 'each': 49,\n",
       " 'have': 50,\n",
       " 'bicycle': 51,\n",
       " 'two': 52,\n",
       " 'cheese': 53,\n",
       " 'tell': 54,\n",
       " 'they’d': 55,\n",
       " 'saw': 56,\n",
       " 'tech': 57,\n",
       " 'cold': 58,\n",
       " 'windows': 59,\n",
       " 'open': 60,\n",
       " 'wear': 61,\n",
       " 'glasses': 62,\n",
       " 'wearing': 63,\n",
       " 'go': 64,\n",
       " 'bar': 65,\n",
       " 'break': 66,\n",
       " 'wall': 67,\n",
       " 'say': 68,\n",
       " 'fish': 69,\n",
       " 'how': 70,\n",
       " 'would': 71,\n",
       " 'construction': 72,\n",
       " 'but': 73,\n",
       " 'still': 74,\n",
       " 'working': 75,\n",
       " 'used': 76,\n",
       " 'now': 77,\n",
       " 'use': 78,\n",
       " 'my': 79,\n",
       " 'long': 80,\n",
       " 'when': 81,\n",
       " 'they’re': 82,\n",
       " 'cows': 83,\n",
       " 'of': 84,\n",
       " 'mouse': 85,\n",
       " 'from': 86,\n",
       " 'factory': 87,\n",
       " 'bring': 88,\n",
       " 'time': 89,\n",
       " 'no': 90,\n",
       " 'dad': 91,\n",
       " 'opener': 92,\n",
       " 'and': 93,\n",
       " 'she': 94,\n",
       " 'collection': 95,\n",
       " 'general': 96,\n",
       " 'scientists': 97,\n",
       " 'atoms': 98,\n",
       " 'math': 99,\n",
       " 'book': 100,\n",
       " 'look': 101,\n",
       " 'sad': 102,\n",
       " 'problems': 103,\n",
       " 'scarecrow': 104,\n",
       " 'win': 105,\n",
       " 'award': 106,\n",
       " 'outstanding': 107,\n",
       " 'field': 108,\n",
       " 'skeletons': 109,\n",
       " 'fight': 110,\n",
       " 'guts': 111,\n",
       " 'fall': 112,\n",
       " 'tired': 113,\n",
       " 'fake': 114,\n",
       " 'spaghetti': 115,\n",
       " 'impasta': 116,\n",
       " 'coffee': 117,\n",
       " 'file': 118,\n",
       " 'police': 119,\n",
       " 'report': 120,\n",
       " 'got': 121,\n",
       " 'mugged': 122,\n",
       " 'isn’t': 123,\n",
       " 'yours': 124,\n",
       " 'nacho': 125,\n",
       " \"don't\": 126,\n",
       " 'eggs': 127,\n",
       " 'crack': 128,\n",
       " 'tomato': 129,\n",
       " 'turn': 130,\n",
       " 'red': 131,\n",
       " 'salad': 132,\n",
       " 'dressing': 133,\n",
       " 'nerdy': 134,\n",
       " 'programmers': 135,\n",
       " 'nature': 136,\n",
       " 'has': 137,\n",
       " 'bugs': 138,\n",
       " 'java': 139,\n",
       " 'developers': 140,\n",
       " 'c': 141,\n",
       " 'cell': 142,\n",
       " 'phone': 143,\n",
       " 'contacts': 144,\n",
       " 'therapy': 145,\n",
       " 'hard': 146,\n",
       " 'drive': 147,\n",
       " 'powerpoint': 148,\n",
       " 'presentation': 149,\n",
       " 'cross': 150,\n",
       " 'road': 151,\n",
       " 'slide': 152,\n",
       " 'computer’s': 153,\n",
       " 'snack': 154,\n",
       " 'microchips': 155,\n",
       " 'atom': 156,\n",
       " 'coder’s': 157,\n",
       " 'hangout': 158,\n",
       " 'place': 159,\n",
       " 'foo': 160,\n",
       " 'guy': 161,\n",
       " 'girlfriend': 162,\n",
       " 'arguments': 163,\n",
       " 'puns': 164,\n",
       " 'wordplay': 165,\n",
       " 'one': 166,\n",
       " 'i’ll': 167,\n",
       " 'meet': 168,\n",
       " 'at': 169,\n",
       " 'corner': 170,\n",
       " 'bowtie': 171,\n",
       " 'sofishticated': 172,\n",
       " 'organize': 173,\n",
       " 'space': 174,\n",
       " 'party': 175,\n",
       " 'planet': 176,\n",
       " 'joke…': 177,\n",
       " 'play': 178,\n",
       " 'piano': 179,\n",
       " 'by': 180,\n",
       " 'ear…': 181,\n",
       " 'hands': 182,\n",
       " 'your': 183,\n",
       " 'nose': 184,\n",
       " '12': 185,\n",
       " 'inches': 186,\n",
       " 'then': 187,\n",
       " 'foot': 188,\n",
       " 'happens': 189,\n",
       " 'frogs': 190,\n",
       " 'park': 191,\n",
       " 'illegally': 192,\n",
       " 'toad': 193,\n",
       " 'rumor': 194,\n",
       " 'butter': 195,\n",
       " 'well': 196,\n",
       " 'not': 197,\n",
       " 'going': 198,\n",
       " 'spread': 199,\n",
       " 'addicted': 200,\n",
       " 'soap…': 201,\n",
       " 'clean': 202,\n",
       " 'oysters': 203,\n",
       " 'donate': 204,\n",
       " 'charity': 205,\n",
       " 'shellfish': 206,\n",
       " 'animal': 207,\n",
       " 'bells': 208,\n",
       " 'their': 209,\n",
       " 'horns': 210,\n",
       " 'chicken': 211,\n",
       " 'séance': 212,\n",
       " 'talk': 213,\n",
       " 'side': 214,\n",
       " 'count': 215,\n",
       " 'cowculator': 216,\n",
       " 'alligator': 217,\n",
       " 'vest': 218,\n",
       " 'investigator': 219,\n",
       " 'elephants': 220,\n",
       " 'computers': 221,\n",
       " 'afraid': 222,\n",
       " 'seagulls': 223,\n",
       " 'fly': 224,\n",
       " 'sea': 225,\n",
       " 'if': 226,\n",
       " 'flew': 227,\n",
       " 'bay': 228,\n",
       " 'bagels': 229,\n",
       " 'pampered': 230,\n",
       " 'cow': 231,\n",
       " 'spoiled': 232,\n",
       " 'milk': 233,\n",
       " 'cat': 234,\n",
       " 'sit': 235,\n",
       " 'keep': 236,\n",
       " 'eye': 237,\n",
       " 'blush': 238,\n",
       " 'ocean’s': 239,\n",
       " 'bottom': 240,\n",
       " 'dogs': 241,\n",
       " 'good': 242,\n",
       " 'dancers': 243,\n",
       " 'feet': 244,\n",
       " 'employee': 245,\n",
       " 'fired': 246,\n",
       " 'calendar': 247,\n",
       " 'took': 248,\n",
       " 'few': 249,\n",
       " 'days': 250,\n",
       " 'off': 251,\n",
       " 'banker': 252,\n",
       " 'quit': 253,\n",
       " 'job': 254,\n",
       " 'interest': 255,\n",
       " 'clock': 256,\n",
       " 'promoted': 257,\n",
       " 'always': 258,\n",
       " 'worked': 259,\n",
       " 'overtime': 260,\n",
       " 'bosses': 261,\n",
       " 'drag': 262,\n",
       " 'stapler': 263,\n",
       " 'paper': 264,\n",
       " 'found': 265,\n",
       " 'clingy': 266,\n",
       " 'pen': 267,\n",
       " 'pencil': 268,\n",
       " \"you're\": 269,\n",
       " 'pointless': 270,\n",
       " 'so': 271,\n",
       " 'ghost’s': 272,\n",
       " 'task': 273,\n",
       " 'spook': 274,\n",
       " 'taking': 275,\n",
       " 'intern': 276,\n",
       " 'wanted': 277,\n",
       " 'climb': 278,\n",
       " 'corporate': 279,\n",
       " 'meetings': 280,\n",
       " 'ever': 281,\n",
       " 'end': 282,\n",
       " 'flies': 283,\n",
       " 'one’s': 284,\n",
       " 'paying': 285,\n",
       " 'attention': 286,\n",
       " 'makes': 287,\n",
       " 'okay': 288,\n",
       " 'products': 289,\n",
       " 'satisfactory': 290,\n",
       " 'restaurant': 291,\n",
       " 'moon': 292,\n",
       " 'great': 293,\n",
       " 'food': 294,\n",
       " 'atmosphere': 295,\n",
       " 'can': 296,\n",
       " 'doesn’t': 297,\n",
       " 'orange': 298,\n",
       " 'sounds': 299,\n",
       " 'parrot': 300,\n",
       " 'carrot': 301,\n",
       " 'want': 302,\n",
       " 'joke': 303,\n",
       " 'sorry': 304,\n",
       " 'brown': 305,\n",
       " 'sticky': 306,\n",
       " 'stick': 307,\n",
       " 'told': 308,\n",
       " 'wife': 309,\n",
       " 'drawing': 310,\n",
       " 'her': 311,\n",
       " 'eyebrows': 312,\n",
       " 'high…': 313,\n",
       " 'looked': 314,\n",
       " 'surprised': 315,\n",
       " 'pile': 316,\n",
       " 'cats': 317,\n",
       " 'meow': 318,\n",
       " 'tain': 319,\n",
       " 'couldn’t': 320,\n",
       " 'find': 321,\n",
       " 'way': 322,\n",
       " 'home': 323,\n",
       " 'bearings': 324,\n",
       " 'heard': 325,\n",
       " 'drinks': 326,\n",
       " 'were': 327,\n",
       " 'house': 328}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ca5c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "919c99f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jokes Collection\n",
      "General Jokes\n",
      "Why don’t scientists trust atoms?\n",
      "Because they make up everything!\n",
      "\n",
      "Why did the math book look sad?\n",
      "Because it had too many problems.\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "Because he was outstanding in his field.\n",
      "\n",
      "Why don’t skeletons fight each other?\n",
      "Because they don’t have the guts.\n",
      "\n",
      "Why did the bicycle fall over?\n",
      "Because it was two-tired.\n",
      "\n",
      "What do you call fake spaghetti?\n",
      "An impasta.\n",
      "\n",
      "Why did the coffee file a police report?\n",
      "It got mugged.\n",
      "\n",
      "What do you call cheese that isn’t yours?\n",
      "Nacho cheese.\n",
      "\n",
      "Why don't eggs tell jokes?\n",
      "Because they’d crack each other up.\n",
      "\n",
      "Why did the tomato turn red?\n",
      "Because it saw the salad dressing.\n",
      "\n",
      "Tech & Nerdy Jokes\n",
      "Why was the computer cold?\n",
      "Because it left its Windows open.\n",
      "\n",
      "Why don’t programmers like nature?\n",
      "It has too many bugs.\n",
      "\n",
      "Why do Java developers wear glasses?\n",
      "Because they don’t C#.\n",
      "\n",
      "Why was the cell phone wearing glasses?\n",
      "Because it lost its contacts.\n",
      "\n",
      "Why did the computer go to therapy?\n",
      "It had a hard drive.\n",
      "\n",
      "Why did the PowerPoint Presentation cross the road?\n",
      "To get to the other slide.\n",
      "\n",
      "What’s a computer’s favorite snack?\n",
      "Microchips.\n",
      "\n",
      "Why can’t you trust an atom?\n",
      "They make up everything.\n",
      "\n",
      "What’s a coder’s favorite hangout place?\n",
      "The Foo Bar.\n",
      "\n",
      "Why did the tech guy break up with his girlfriend?\n",
      "Too many arguments.\n",
      "\n",
      "Puns & Wordplay\n",
      "What did one wall say to the other wall?\n",
      "I’ll meet you at the corner.\n",
      "\n",
      "What do you call a fish wearing a bowtie?\n",
      "Sofishticated.\n",
      "\n",
      "How do you organize a space party?\n",
      "You planet.\n",
      "\n",
      "I would tell you a construction joke…\n",
      "But I’m still working on it.\n",
      "\n",
      "I used to play piano by ear…\n",
      "Now I use my hands.\n",
      "\n",
      "Why can’t your nose be 12 inches long?\n",
      "Because then it would be a foot.\n",
      "\n",
      "What happens when frogs park illegally?\n",
      "They get toad.\n",
      "\n",
      "Did you hear the rumor about butter?\n",
      "Well, I’m not going to spread it.\n",
      "\n",
      "I used to be addicted to soap…\n",
      "But I’m clean now.\n",
      "\n",
      "Why don’t oysters donate to charity?\n",
      "Because they’re shellfish.\n",
      "\n",
      "Animal Jokes\n",
      "Why do cows wear bells?\n",
      "Because their horns don’t work.\n",
      "\n",
      "Why did the chicken go to the séance?\n",
      "To talk to the other side.\n",
      "\n",
      "How do you count cows?\n",
      "With a cowculator.\n",
      "\n",
      "What do you call an alligator in a vest?\n",
      "An investigator.\n",
      "\n",
      "Why don’t elephants use computers?\n",
      "They’re afraid of the mouse.\n",
      "\n",
      "Why do seagulls fly over the sea?\n",
      "Because if they flew over the bay, they’d be bagels.\n",
      "\n",
      "What do you get from a pampered cow?\n",
      "Spoiled milk.\n",
      "\n",
      "Why did the cat sit on the computer?\n",
      "To keep an eye on the mouse.\n",
      "\n",
      "Why did the fish blush?\n",
      "Because it saw the ocean’s bottom.\n",
      "\n",
      "Why don’t dogs make good dancers?\n",
      "Because they have two left feet.\n",
      "\n",
      "Office & Work Jokes\n",
      "Why did the employee get fired from the calendar factory?\n",
      "He took a few days off.\n",
      "\n",
      "Why did the banker quit his job?\n",
      "He lost interest.\n",
      "\n",
      "Why did the clock get promoted?\n",
      "It always worked overtime.\n",
      "\n",
      "Why don’t bosses like long jokes?\n",
      "Because they drag on.\n",
      "\n",
      "Why did the stapler break up with the paper?\n",
      "It found it too clingy.\n",
      "\n",
      "What did the pen say to the pencil?\n",
      "You're pointless.\n",
      "\n",
      "Why was the office so cold?\n",
      "Because they left too many Windows open.\n",
      "\n",
      "What’s a ghost’s favorite office task?\n",
      "Spook-taking.\n",
      "\n",
      "Why did the intern bring a ladder to work?\n",
      "He wanted to climb the corporate ladder.\n",
      "\n",
      "Why don’t meetings ever end on time?\n",
      "Because time flies when no one’s paying attention.\n",
      "\n",
      "Dad Jokes\n",
      "What do you call a factory that makes okay products?\n",
      "A satisfactory.\n",
      "\n",
      "Did you hear about the restaurant on the moon?\n",
      "Great food, no atmosphere.\n",
      "\n",
      "What do you call a can opener that doesn’t work?\n",
      "A can’t opener.\n",
      "\n",
      "What’s orange and sounds like a parrot?\n",
      "A carrot.\n",
      "\n",
      "Want to hear a joke about construction?\n",
      "Sorry, I’m still working on it.\n",
      "\n",
      "What’s brown and sticky?\n",
      "A stick.\n",
      "\n",
      "I told my wife she was drawing her eyebrows too high…\n",
      "She looked surprised.\n",
      "\n",
      "What do you call a pile of cats?\n",
      "A meow-tain.\n",
      "\n",
      "Why couldn’t the bicycle find its way home?\n",
      "Because it lost its bearings.\n",
      "\n",
      "Why did the dad bring a ladder to the bar?\n",
      "Because he heard the drinks were on the house.\n"
     ]
    }
   ],
   "source": [
    "for sentence in jokes.split('\\n'):\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a24f0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentence in jokes.split('\\n'):\n",
    "    tokenized_sentences=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(tokenized_sentences)):\n",
    "        input_sequences.append(tokenized_sentences[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06a3e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 95],\n",
       " [96, 13],\n",
       " [2, 10],\n",
       " [2, 10, 97],\n",
       " [2, 10, 97, 45],\n",
       " [2, 10, 97, 45, 98],\n",
       " [4, 12],\n",
       " [4, 12, 30],\n",
       " [4, 12, 30, 19],\n",
       " [4, 12, 30, 19, 46],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 99],\n",
       " [2, 5, 1, 99, 100],\n",
       " [2, 5, 1, 99, 100, 101],\n",
       " [2, 5, 1, 99, 100, 101, 102],\n",
       " [4, 7],\n",
       " [4, 7, 47],\n",
       " [4, 7, 47, 16],\n",
       " [4, 7, 47, 16, 25],\n",
       " [4, 7, 47, 16, 25, 103],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 104],\n",
       " [2, 5, 1, 104, 105],\n",
       " [2, 5, 1, 104, 105, 17],\n",
       " [2, 5, 1, 104, 105, 17, 106],\n",
       " [4, 20],\n",
       " [4, 20, 18],\n",
       " [4, 20, 18, 107],\n",
       " [4, 20, 18, 107, 48],\n",
       " [4, 20, 18, 107, 48, 31],\n",
       " [4, 20, 18, 107, 48, 31, 108],\n",
       " [2, 10],\n",
       " [2, 10, 109],\n",
       " [2, 10, 109, 110],\n",
       " [2, 10, 109, 110, 49],\n",
       " [2, 10, 109, 110, 49, 21],\n",
       " [4, 12],\n",
       " [4, 12, 10],\n",
       " [4, 12, 10, 50],\n",
       " [4, 12, 10, 50, 1],\n",
       " [4, 12, 10, 50, 1, 111],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 51],\n",
       " [2, 5, 1, 51, 112],\n",
       " [2, 5, 1, 51, 112, 32],\n",
       " [4, 7],\n",
       " [4, 7, 18],\n",
       " [4, 7, 18, 52],\n",
       " [4, 7, 18, 52, 113],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 114],\n",
       " [11, 9, 8, 15, 114, 115],\n",
       " [17, 116],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 117],\n",
       " [2, 5, 1, 117, 118],\n",
       " [2, 5, 1, 117, 118, 3],\n",
       " [2, 5, 1, 117, 118, 3, 119],\n",
       " [2, 5, 1, 117, 118, 3, 119, 120],\n",
       " [7, 121],\n",
       " [7, 121, 122],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 53],\n",
       " [11, 9, 8, 15, 53, 33],\n",
       " [11, 9, 8, 15, 53, 33, 123],\n",
       " [11, 9, 8, 15, 53, 33, 123, 124],\n",
       " [125, 53],\n",
       " [2, 126],\n",
       " [2, 126, 127],\n",
       " [2, 126, 127, 54],\n",
       " [2, 126, 127, 54, 13],\n",
       " [4, 55],\n",
       " [4, 55, 128],\n",
       " [4, 55, 128, 49],\n",
       " [4, 55, 128, 49, 21],\n",
       " [4, 55, 128, 49, 21, 19],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 129],\n",
       " [2, 5, 1, 129, 130],\n",
       " [2, 5, 1, 129, 130, 131],\n",
       " [4, 7],\n",
       " [4, 7, 56],\n",
       " [4, 7, 56, 1],\n",
       " [4, 7, 56, 1, 132],\n",
       " [4, 7, 56, 1, 132, 133],\n",
       " [57, 134],\n",
       " [57, 134, 13],\n",
       " [2, 18],\n",
       " [2, 18, 1],\n",
       " [2, 18, 1, 34],\n",
       " [2, 18, 1, 34, 58],\n",
       " [4, 7],\n",
       " [4, 7, 35],\n",
       " [4, 7, 35, 26],\n",
       " [4, 7, 35, 26, 59],\n",
       " [4, 7, 35, 26, 59, 60],\n",
       " [2, 10],\n",
       " [2, 10, 135],\n",
       " [2, 10, 135, 36],\n",
       " [2, 10, 135, 36, 136],\n",
       " [7, 137],\n",
       " [7, 137, 16],\n",
       " [7, 137, 16, 25],\n",
       " [7, 137, 16, 25, 138],\n",
       " [2, 9],\n",
       " [2, 9, 139],\n",
       " [2, 9, 139, 140],\n",
       " [2, 9, 139, 140, 61],\n",
       " [2, 9, 139, 140, 61, 62],\n",
       " [4, 12],\n",
       " [4, 12, 10],\n",
       " [4, 12, 10, 141],\n",
       " [2, 18],\n",
       " [2, 18, 1],\n",
       " [2, 18, 1, 142],\n",
       " [2, 18, 1, 142, 143],\n",
       " [2, 18, 1, 142, 143, 63],\n",
       " [2, 18, 1, 142, 143, 63, 62],\n",
       " [4, 7],\n",
       " [4, 7, 37],\n",
       " [4, 7, 37, 26],\n",
       " [4, 7, 37, 26, 144],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 34],\n",
       " [2, 5, 1, 34, 64],\n",
       " [2, 5, 1, 34, 64, 6],\n",
       " [2, 5, 1, 34, 64, 6, 145],\n",
       " [7, 47],\n",
       " [7, 47, 3],\n",
       " [7, 47, 3, 146],\n",
       " [7, 47, 3, 146, 147],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 148],\n",
       " [2, 5, 1, 148, 149],\n",
       " [2, 5, 1, 148, 149, 150],\n",
       " [2, 5, 1, 148, 149, 150, 1],\n",
       " [2, 5, 1, 148, 149, 150, 1, 151],\n",
       " [6, 22],\n",
       " [6, 22, 6],\n",
       " [6, 22, 6, 1],\n",
       " [6, 22, 6, 1, 21],\n",
       " [6, 22, 6, 1, 21, 152],\n",
       " [23, 3],\n",
       " [23, 3, 153],\n",
       " [23, 3, 153, 38],\n",
       " [23, 3, 153, 38, 154],\n",
       " [2, 39],\n",
       " [2, 39, 8],\n",
       " [2, 39, 8, 45],\n",
       " [2, 39, 8, 45, 17],\n",
       " [2, 39, 8, 45, 17, 156],\n",
       " [12, 30],\n",
       " [12, 30, 19],\n",
       " [12, 30, 19, 46],\n",
       " [23, 3],\n",
       " [23, 3, 157],\n",
       " [23, 3, 157, 38],\n",
       " [23, 3, 157, 38, 158],\n",
       " [23, 3, 157, 38, 158, 159],\n",
       " [1, 160],\n",
       " [1, 160, 65],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 57],\n",
       " [2, 5, 1, 57, 161],\n",
       " [2, 5, 1, 57, 161, 66],\n",
       " [2, 5, 1, 57, 161, 66, 19],\n",
       " [2, 5, 1, 57, 161, 66, 19, 40],\n",
       " [2, 5, 1, 57, 161, 66, 19, 40, 31],\n",
       " [2, 5, 1, 57, 161, 66, 19, 40, 31, 162],\n",
       " [16, 25],\n",
       " [16, 25, 163],\n",
       " [164, 165],\n",
       " [11, 5],\n",
       " [11, 5, 166],\n",
       " [11, 5, 166, 67],\n",
       " [11, 5, 166, 67, 68],\n",
       " [11, 5, 166, 67, 68, 6],\n",
       " [11, 5, 166, 67, 68, 6, 1],\n",
       " [11, 5, 166, 67, 68, 6, 1, 21],\n",
       " [11, 5, 166, 67, 68, 6, 1, 21, 67],\n",
       " [167, 168],\n",
       " [167, 168, 8],\n",
       " [167, 168, 8, 169],\n",
       " [167, 168, 8, 169, 1],\n",
       " [167, 168, 8, 169, 1, 170],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 3],\n",
       " [11, 9, 8, 15, 3, 69],\n",
       " [11, 9, 8, 15, 3, 69, 63],\n",
       " [11, 9, 8, 15, 3, 69, 63, 3],\n",
       " [11, 9, 8, 15, 3, 69, 63, 3, 171],\n",
       " [70, 9],\n",
       " [70, 9, 8],\n",
       " [70, 9, 8, 173],\n",
       " [70, 9, 8, 173, 3],\n",
       " [70, 9, 8, 173, 3, 174],\n",
       " [70, 9, 8, 173, 3, 174, 175],\n",
       " [8, 176],\n",
       " [24, 71],\n",
       " [24, 71, 54],\n",
       " [24, 71, 54, 8],\n",
       " [24, 71, 54, 8, 3],\n",
       " [24, 71, 54, 8, 3, 72],\n",
       " [24, 71, 54, 8, 3, 72, 177],\n",
       " [73, 27],\n",
       " [73, 27, 74],\n",
       " [73, 27, 74, 75],\n",
       " [73, 27, 74, 75, 14],\n",
       " [73, 27, 74, 75, 14, 7],\n",
       " [24, 76],\n",
       " [24, 76, 6],\n",
       " [24, 76, 6, 178],\n",
       " [24, 76, 6, 178, 179],\n",
       " [24, 76, 6, 178, 179, 180],\n",
       " [24, 76, 6, 178, 179, 180, 181],\n",
       " [77, 24],\n",
       " [77, 24, 78],\n",
       " [77, 24, 78, 79],\n",
       " [77, 24, 78, 79, 182],\n",
       " [2, 39],\n",
       " [2, 39, 183],\n",
       " [2, 39, 183, 184],\n",
       " [2, 39, 183, 184, 28],\n",
       " [2, 39, 183, 184, 28, 185],\n",
       " [2, 39, 183, 184, 28, 185, 186],\n",
       " [2, 39, 183, 184, 28, 185, 186, 80],\n",
       " [4, 187],\n",
       " [4, 187, 7],\n",
       " [4, 187, 7, 71],\n",
       " [4, 187, 7, 71, 28],\n",
       " [4, 187, 7, 71, 28, 3],\n",
       " [4, 187, 7, 71, 28, 3, 188],\n",
       " [11, 189],\n",
       " [11, 189, 81],\n",
       " [11, 189, 81, 190],\n",
       " [11, 189, 81, 190, 191],\n",
       " [11, 189, 81, 190, 191, 192],\n",
       " [12, 22],\n",
       " [12, 22, 193],\n",
       " [5, 8],\n",
       " [5, 8, 41],\n",
       " [5, 8, 41, 1],\n",
       " [5, 8, 41, 1, 194],\n",
       " [5, 8, 41, 1, 194, 42],\n",
       " [5, 8, 41, 1, 194, 42, 195],\n",
       " [196, 27],\n",
       " [196, 27, 197],\n",
       " [196, 27, 197, 198],\n",
       " [196, 27, 197, 198, 6],\n",
       " [196, 27, 197, 198, 6, 199],\n",
       " [196, 27, 197, 198, 6, 199, 7],\n",
       " [24, 76],\n",
       " [24, 76, 6],\n",
       " [24, 76, 6, 28],\n",
       " [24, 76, 6, 28, 200],\n",
       " [24, 76, 6, 28, 200, 6],\n",
       " [24, 76, 6, 28, 200, 6, 201],\n",
       " [73, 27],\n",
       " [73, 27, 202],\n",
       " [73, 27, 202, 77],\n",
       " [2, 10],\n",
       " [2, 10, 203],\n",
       " [2, 10, 203, 204],\n",
       " [2, 10, 203, 204, 6],\n",
       " [2, 10, 203, 204, 6, 205],\n",
       " [4, 82],\n",
       " [4, 82, 206],\n",
       " [207, 13],\n",
       " [2, 9],\n",
       " [2, 9, 83],\n",
       " [2, 9, 83, 61],\n",
       " [2, 9, 83, 61, 208],\n",
       " [4, 209],\n",
       " [4, 209, 210],\n",
       " [4, 209, 210, 10],\n",
       " [4, 209, 210, 10, 29],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 211],\n",
       " [2, 5, 1, 211, 64],\n",
       " [2, 5, 1, 211, 64, 6],\n",
       " [2, 5, 1, 211, 64, 6, 1],\n",
       " [2, 5, 1, 211, 64, 6, 1, 212],\n",
       " [6, 213],\n",
       " [6, 213, 6],\n",
       " [6, 213, 6, 1],\n",
       " [6, 213, 6, 1, 21],\n",
       " [6, 213, 6, 1, 21, 214],\n",
       " [70, 9],\n",
       " [70, 9, 8],\n",
       " [70, 9, 8, 215],\n",
       " [70, 9, 8, 215, 83],\n",
       " [40, 3],\n",
       " [40, 3, 216],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 17],\n",
       " [11, 9, 8, 15, 17, 217],\n",
       " [11, 9, 8, 15, 17, 217, 48],\n",
       " [11, 9, 8, 15, 17, 217, 48, 3],\n",
       " [11, 9, 8, 15, 17, 217, 48, 3, 218],\n",
       " [17, 219],\n",
       " [2, 10],\n",
       " [2, 10, 220],\n",
       " [2, 10, 220, 78],\n",
       " [2, 10, 220, 78, 221],\n",
       " [82, 222],\n",
       " [82, 222, 84],\n",
       " [82, 222, 84, 1],\n",
       " [82, 222, 84, 1, 85],\n",
       " [2, 9],\n",
       " [2, 9, 223],\n",
       " [2, 9, 223, 224],\n",
       " [2, 9, 223, 224, 32],\n",
       " [2, 9, 223, 224, 32, 1],\n",
       " [2, 9, 223, 224, 32, 1, 225],\n",
       " [4, 226],\n",
       " [4, 226, 12],\n",
       " [4, 226, 12, 227],\n",
       " [4, 226, 12, 227, 32],\n",
       " [4, 226, 12, 227, 32, 1],\n",
       " [4, 226, 12, 227, 32, 1, 228],\n",
       " [4, 226, 12, 227, 32, 1, 228, 55],\n",
       " [4, 226, 12, 227, 32, 1, 228, 55, 28],\n",
       " [4, 226, 12, 227, 32, 1, 228, 55, 28, 229],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 22],\n",
       " [11, 9, 8, 22, 86],\n",
       " [11, 9, 8, 22, 86, 3],\n",
       " [11, 9, 8, 22, 86, 3, 230],\n",
       " [11, 9, 8, 22, 86, 3, 230, 231],\n",
       " [232, 233],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 234],\n",
       " [2, 5, 1, 234, 235],\n",
       " [2, 5, 1, 234, 235, 14],\n",
       " [2, 5, 1, 234, 235, 14, 1],\n",
       " [2, 5, 1, 234, 235, 14, 1, 34],\n",
       " [6, 236],\n",
       " [6, 236, 17],\n",
       " [6, 236, 17, 237],\n",
       " [6, 236, 17, 237, 14],\n",
       " [6, 236, 17, 237, 14, 1],\n",
       " [6, 236, 17, 237, 14, 1, 85],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 69],\n",
       " [2, 5, 1, 69, 238],\n",
       " [4, 7],\n",
       " [4, 7, 56],\n",
       " [4, 7, 56, 1],\n",
       " [4, 7, 56, 1, 239],\n",
       " [4, 7, 56, 1, 239, 240],\n",
       " [2, 10],\n",
       " [2, 10, 241],\n",
       " [2, 10, 241, 30],\n",
       " [2, 10, 241, 30, 242],\n",
       " [2, 10, 241, 30, 242, 243],\n",
       " [4, 12],\n",
       " [4, 12, 50],\n",
       " [4, 12, 50, 52],\n",
       " [4, 12, 50, 52, 35],\n",
       " [4, 12, 50, 52, 35, 244],\n",
       " [43, 29],\n",
       " [43, 29, 13],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 245],\n",
       " [2, 5, 1, 245, 22],\n",
       " [2, 5, 1, 245, 22, 246],\n",
       " [2, 5, 1, 245, 22, 246, 86],\n",
       " [2, 5, 1, 245, 22, 246, 86, 1],\n",
       " [2, 5, 1, 245, 22, 246, 86, 1, 247],\n",
       " [2, 5, 1, 245, 22, 246, 86, 1, 247, 87],\n",
       " [20, 248],\n",
       " [20, 248, 3],\n",
       " [20, 248, 3, 249],\n",
       " [20, 248, 3, 249, 250],\n",
       " [20, 248, 3, 249, 250, 251],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 252],\n",
       " [2, 5, 1, 252, 253],\n",
       " [2, 5, 1, 252, 253, 31],\n",
       " [2, 5, 1, 252, 253, 31, 254],\n",
       " [20, 37],\n",
       " [20, 37, 255],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 256],\n",
       " [2, 5, 1, 256, 22],\n",
       " [2, 5, 1, 256, 22, 257],\n",
       " [7, 258],\n",
       " [7, 258, 259],\n",
       " [7, 258, 259, 260],\n",
       " [2, 10],\n",
       " [2, 10, 261],\n",
       " [2, 10, 261, 36],\n",
       " [2, 10, 261, 36, 80],\n",
       " [2, 10, 261, 36, 80, 13],\n",
       " [4, 12],\n",
       " [4, 12, 262],\n",
       " [4, 12, 262, 14],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 263],\n",
       " [2, 5, 1, 263, 66],\n",
       " [2, 5, 1, 263, 66, 19],\n",
       " [2, 5, 1, 263, 66, 19, 40],\n",
       " [2, 5, 1, 263, 66, 19, 40, 1],\n",
       " [2, 5, 1, 263, 66, 19, 40, 1, 264],\n",
       " [7, 265],\n",
       " [7, 265, 7],\n",
       " [7, 265, 7, 16],\n",
       " [7, 265, 7, 16, 266],\n",
       " [11, 5],\n",
       " [11, 5, 1],\n",
       " [11, 5, 1, 267],\n",
       " [11, 5, 1, 267, 68],\n",
       " [11, 5, 1, 267, 68, 6],\n",
       " [11, 5, 1, 267, 68, 6, 1],\n",
       " [11, 5, 1, 267, 68, 6, 1, 268],\n",
       " [269, 270],\n",
       " [2, 18],\n",
       " [2, 18, 1],\n",
       " [2, 18, 1, 43],\n",
       " [2, 18, 1, 43, 271],\n",
       " [2, 18, 1, 43, 271, 58],\n",
       " [4, 12],\n",
       " [4, 12, 35],\n",
       " [4, 12, 35, 16],\n",
       " [4, 12, 35, 16, 25],\n",
       " [4, 12, 35, 16, 25, 59],\n",
       " [4, 12, 35, 16, 25, 59, 60],\n",
       " [23, 3],\n",
       " [23, 3, 272],\n",
       " [23, 3, 272, 38],\n",
       " [23, 3, 272, 38, 43],\n",
       " [23, 3, 272, 38, 43, 273],\n",
       " [274, 275],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 276],\n",
       " [2, 5, 1, 276, 88],\n",
       " [2, 5, 1, 276, 88, 3],\n",
       " [2, 5, 1, 276, 88, 3, 44],\n",
       " [2, 5, 1, 276, 88, 3, 44, 6],\n",
       " [2, 5, 1, 276, 88, 3, 44, 6, 29],\n",
       " [20, 277],\n",
       " [20, 277, 6],\n",
       " [20, 277, 6, 278],\n",
       " [20, 277, 6, 278, 1],\n",
       " [20, 277, 6, 278, 1, 279],\n",
       " [20, 277, 6, 278, 1, 279, 44],\n",
       " [2, 10],\n",
       " [2, 10, 280],\n",
       " [2, 10, 280, 281],\n",
       " [2, 10, 280, 281, 282],\n",
       " [2, 10, 280, 281, 282, 14],\n",
       " [2, 10, 280, 281, 282, 14, 89],\n",
       " [4, 89],\n",
       " [4, 89, 283],\n",
       " [4, 89, 283, 81],\n",
       " [4, 89, 283, 81, 90],\n",
       " [4, 89, 283, 81, 90, 284],\n",
       " [4, 89, 283, 81, 90, 284, 285],\n",
       " [4, 89, 283, 81, 90, 284, 285, 286],\n",
       " [91, 13],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 3],\n",
       " [11, 9, 8, 15, 3, 87],\n",
       " [11, 9, 8, 15, 3, 87, 33],\n",
       " [11, 9, 8, 15, 3, 87, 33, 287],\n",
       " [11, 9, 8, 15, 3, 87, 33, 287, 288],\n",
       " [11, 9, 8, 15, 3, 87, 33, 287, 288, 289],\n",
       " [3, 290],\n",
       " [5, 8],\n",
       " [5, 8, 41],\n",
       " [5, 8, 41, 42],\n",
       " [5, 8, 41, 42, 1],\n",
       " [5, 8, 41, 42, 1, 291],\n",
       " [5, 8, 41, 42, 1, 291, 14],\n",
       " [5, 8, 41, 42, 1, 291, 14, 1],\n",
       " [5, 8, 41, 42, 1, 291, 14, 1, 292],\n",
       " [293, 294],\n",
       " [293, 294, 90],\n",
       " [293, 294, 90, 295],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 3],\n",
       " [11, 9, 8, 15, 3, 296],\n",
       " [11, 9, 8, 15, 3, 296, 92],\n",
       " [11, 9, 8, 15, 3, 296, 92, 33],\n",
       " [11, 9, 8, 15, 3, 296, 92, 33, 297],\n",
       " [11, 9, 8, 15, 3, 296, 92, 33, 297, 29],\n",
       " [3, 39],\n",
       " [3, 39, 92],\n",
       " [23, 298],\n",
       " [23, 298, 93],\n",
       " [23, 298, 93, 299],\n",
       " [23, 298, 93, 299, 36],\n",
       " [23, 298, 93, 299, 36, 3],\n",
       " [23, 298, 93, 299, 36, 3, 300],\n",
       " [3, 301],\n",
       " [302, 6],\n",
       " [302, 6, 41],\n",
       " [302, 6, 41, 3],\n",
       " [302, 6, 41, 3, 303],\n",
       " [302, 6, 41, 3, 303, 42],\n",
       " [302, 6, 41, 3, 303, 42, 72],\n",
       " [304, 27],\n",
       " [304, 27, 74],\n",
       " [304, 27, 74, 75],\n",
       " [304, 27, 74, 75, 14],\n",
       " [304, 27, 74, 75, 14, 7],\n",
       " [23, 305],\n",
       " [23, 305, 93],\n",
       " [23, 305, 93, 306],\n",
       " [3, 307],\n",
       " [24, 308],\n",
       " [24, 308, 79],\n",
       " [24, 308, 79, 309],\n",
       " [24, 308, 79, 309, 94],\n",
       " [24, 308, 79, 309, 94, 18],\n",
       " [24, 308, 79, 309, 94, 18, 310],\n",
       " [24, 308, 79, 309, 94, 18, 310, 311],\n",
       " [24, 308, 79, 309, 94, 18, 310, 311, 312],\n",
       " [24, 308, 79, 309, 94, 18, 310, 311, 312, 16],\n",
       " [24, 308, 79, 309, 94, 18, 310, 311, 312, 16, 313],\n",
       " [94, 314],\n",
       " [94, 314, 315],\n",
       " [11, 9],\n",
       " [11, 9, 8],\n",
       " [11, 9, 8, 15],\n",
       " [11, 9, 8, 15, 3],\n",
       " [11, 9, 8, 15, 3, 316],\n",
       " [11, 9, 8, 15, 3, 316, 84],\n",
       " [11, 9, 8, 15, 3, 316, 84, 317],\n",
       " [3, 318],\n",
       " [3, 318, 319],\n",
       " [2, 320],\n",
       " [2, 320, 1],\n",
       " [2, 320, 1, 51],\n",
       " [2, 320, 1, 51, 321],\n",
       " [2, 320, 1, 51, 321, 26],\n",
       " [2, 320, 1, 51, 321, 26, 322],\n",
       " [2, 320, 1, 51, 321, 26, 322, 323],\n",
       " [4, 7],\n",
       " [4, 7, 37],\n",
       " [4, 7, 37, 26],\n",
       " [4, 7, 37, 26, 324],\n",
       " [2, 5],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1, 91],\n",
       " [2, 5, 1, 91, 88],\n",
       " [2, 5, 1, 91, 88, 3],\n",
       " [2, 5, 1, 91, 88, 3, 44],\n",
       " [2, 5, 1, 91, 88, 3, 44, 6],\n",
       " [2, 5, 1, 91, 88, 3, 44, 6, 1],\n",
       " [2, 5, 1, 91, 88, 3, 44, 6, 1, 65],\n",
       " [4, 20],\n",
       " [4, 20, 325],\n",
       " [4, 20, 325, 1],\n",
       " [4, 20, 325, 1, 326],\n",
       " [4, 20, 325, 1, 326, 327],\n",
       " [4, 20, 325, 1, 326, 327, 14],\n",
       " [4, 20, 325, 1, 326, 327, 14, 1],\n",
       " [4, 20, 325, 1, 326, 327, 14, 1, 328]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753925d",
   "metadata": {},
   "source": [
    "##### Zero Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9158cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33b16cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input=pad_sequences(input_sequences,maxlen=max_len,padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2adc9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=padded_input[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1ccc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=padded_input[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bfd8914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "478dfcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5745c44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6c1dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b187c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 329)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26bda0",
   "metadata": {},
   "source": [
    "#### **Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b91a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f376e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mzees\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# vocab  size= 282 ,output dense = 100, input rows = 56\n",
    "model.add(Embedding(329,100,input_length=10))\n",
    "# 150 nodes for lstm are good for my data\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(329,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17b607f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71cb77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ee754ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">329</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,679</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m32,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m329\u001b[0m)            │        \u001b[38;5;34m49,679\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,179</span> (910.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m233,179\u001b[0m (910.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">233,179</span> (910.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m233,179\u001b[0m (910.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a6bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.0606 - loss: 5.7800\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0764 - loss: 5.2914\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0784 - loss: 5.2436\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0951 - loss: 5.0591\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0947 - loss: 5.1237\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1045 - loss: 5.0127\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1399 - loss: 4.7224\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1290 - loss: 4.7893\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1423 - loss: 4.5494\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1422 - loss: 4.3927\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1470 - loss: 4.2581\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1692 - loss: 4.0627\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2017 - loss: 3.9376\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2137 - loss: 3.7774\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2274 - loss: 3.6082\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2572 - loss: 3.4339\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2527 - loss: 3.3480\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3247 - loss: 3.1200\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3292 - loss: 3.0075\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3476 - loss: 2.9174\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3587 - loss: 2.7916\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4071 - loss: 2.6161\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4656 - loss: 2.4730\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4558 - loss: 2.4115\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5046 - loss: 2.2298\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5506 - loss: 2.0748\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5935 - loss: 2.0240\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5803 - loss: 1.9108\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6700 - loss: 1.7695\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6721 - loss: 1.6770\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6648 - loss: 1.6555\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7234 - loss: 1.5245\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7060 - loss: 1.4972\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7264 - loss: 1.3679\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7363 - loss: 1.3429\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7192 - loss: 1.3349\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7436 - loss: 1.2561\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7550 - loss: 1.1944\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7608 - loss: 1.1706\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7586 - loss: 1.0569\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7962 - loss: 1.0422\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7539 - loss: 1.0293\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7888 - loss: 0.9542\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 1.0287\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7853 - loss: 0.9475\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.8669\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8002 - loss: 0.8442\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7986 - loss: 0.8299\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8188 - loss: 0.8110\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8029 - loss: 0.7961\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8298 - loss: 0.7451\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8226 - loss: 0.7208\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8027 - loss: 0.7604\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8134 - loss: 0.7541\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8182 - loss: 0.6961\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8257 - loss: 0.6638\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7928 - loss: 0.7281\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8002 - loss: 0.6817\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8092 - loss: 0.6663\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8212 - loss: 0.6470\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7783 - loss: 0.6851\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7746 - loss: 0.7025\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8206 - loss: 0.6136\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8158 - loss: 0.5919\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7960 - loss: 0.6325\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7857 - loss: 0.6535\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7977 - loss: 0.6201\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8046 - loss: 0.5884\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8190 - loss: 0.5729\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8043 - loss: 0.6136\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8124 - loss: 0.6001\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 0.6147\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7917 - loss: 0.5706\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7888 - loss: 0.6030\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8047 - loss: 0.5736\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8050 - loss: 0.5748\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8052 - loss: 0.5722\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8165 - loss: 0.5205\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7918 - loss: 0.5511\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8056 - loss: 0.5484\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8179 - loss: 0.5542\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7977 - loss: 0.5371\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7891 - loss: 0.5696\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8093 - loss: 0.5501\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8007 - loss: 0.5288\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8082 - loss: 0.5438\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8311 - loss: 0.4546\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7923 - loss: 0.5696\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7969 - loss: 0.5448\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8086 - loss: 0.5222\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8096 - loss: 0.4839\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8120 - loss: 0.4926\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7934 - loss: 0.5575\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7982 - loss: 0.5245\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7883 - loss: 0.5262\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8051 - loss: 0.5480\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.5067\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8036 - loss: 0.5033\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7841 - loss: 0.5390\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8051 - loss: 0.4882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x166e6b65810>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "840b59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f1e46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "How do you make a tissue dance? cowculator\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "How do you make a tissue dance? cowculator favorite\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "How do you make a tissue dance? cowculator favorite park\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere task\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere task task\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere task task task\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere task task task task\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "How do you make a tissue dance? cowculator favorite park office atmosphere task task task task task\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"How do you make a tissue dance?\"\n",
    "\n",
    "for i in range(10):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
